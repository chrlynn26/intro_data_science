{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project - Link Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the final project, I identified key algorithms for generating social netowrks and also predicted edges using machine learning. \n",
    "\n",
    "In Part 1, I identified randomly generated NetworkX graphs based on their degree distributions. \n",
    "\n",
    "In Part 2, I evaluated an employee social network to determine which employees received a management position salary. The final task involved creating a machine learning classifier to find the probability that coworkers will form a future connection together.\n",
    "\n",
    "---\n",
    "## Part 1 - Random Graph Identification\n",
    "\n",
    "**For part 1, evaluate the 5 networkx graphs available in the list, `P1_Graphs`.**\n",
    "\n",
    "Each of these graphs were generated by **one of three possible algorithms**:\n",
    "* Preferential Attachment (`'PA'`)\n",
    "* Small World with low probability of rewiring (`'SW_L'`)\n",
    "* Small World with high probability of rewiring (`'SW_H'`)\n",
    "\n",
    "### Analyze each of the 5 graphs and determine which of the three algorithms generated each graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "P1_Graphs = pickle.load(open('A4_graphs','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree Distribution Size:  29 Avg. Clustering Coefficient:  0.03167539146454044 Avg. Shortest Path Length:  4.099161161161161\n",
      "Degree Distribution Size:  7 Avg. Clustering Coefficient:  0.5642419635919628 Avg. Shortest Path Length:  5.089871871871872\n",
      "Degree Distribution Size:  5 Avg. Clustering Coefficient:  0.4018222222222227 Avg. Shortest Path Length:  9.378702269692925\n",
      "Degree Distribution Size:  37 Avg. Clustering Coefficient:  0.03780379975223251 Avg. Shortest Path Length:  3.1048046283934134\n",
      "Degree Distribution Size:  9 Avg. Clustering Coefficient:  0.0033037037037037037 Avg. Shortest Path Length:  5.0785509568313305\n",
      "Average degree distribution size:  17.4\n"
     ]
    }
   ],
   "source": [
    "def degree_dist(G):\n",
    "    \n",
    "    # Degree values for graph\n",
    "    degrees = G.degree().values()\n",
    "    sorted_deg = sorted(set(degrees))\n",
    "    \n",
    "    dist = [list(degrees).count(i) / float(nx.number_of_nodes(G)) for i in sorted_deg]\n",
    "    return dist\n",
    "\n",
    "# Degree distribution length. Use for assessing preferential attachment:\n",
    "dist = []\n",
    "# Note: Small-world networks tend to have 1) high clustering coefficients and 2) low average shortest path values\n",
    "for G in P1_Graphs:\n",
    "    print(\"Degree Distribution Size: \", len(degree_dist(G)), \n",
    "          \"Avg. Clustering Coefficient: \", nx.average_clustering(G),\n",
    "          \"Avg. Shortest Path Length: \", nx.average_shortest_path_length(G))\n",
    "    dist.append(len(degree_dist(G)))\n",
    "    \n",
    "# For all graphs..\n",
    "avg_dist = np.mean(dist)\n",
    "print(\"Average degree distribution size: \", avg_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PA', 'SW_L', 'SW_L', 'PA', 'SW_H']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def graph_identification():\n",
    "\n",
    "\n",
    "    # List of possible algorithms for generating each graph\n",
    "    algos = []\n",
    "     \n",
    "    for G in P1_Graphs:\n",
    "        # Degree distribution histogram\n",
    "        hist = degree_dist(G)\n",
    "        # Average clustering coefficient for all 5 random graph\n",
    "        clustering = nx.average_clustering(G)\n",
    "        \n",
    "        if len(hist) > avg_dist:\n",
    "            algos.append('PA')\n",
    "        ## Note: Small-world networks are more likely to rewire with a low clustering coefficient\n",
    "        elif clustering < 0.1:\n",
    "            algos.append('SW_H')\n",
    "        else: \n",
    "            algos.append('SW_L')\n",
    "        \n",
    "    return algos\n",
    "\n",
    "graph_identification()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2 - Company Emails\n",
    "\n",
    "For part 2, **analyze a company's email network**, where each node corresponds to a person at the company, and each edge indicates that at least one email has been sent between two people.\n",
    "\n",
    "<br>\n",
    "*Helpful Hints*:\n",
    "\n",
    "The network contains the node attributes `Department` and `ManagementSalary`.\n",
    "\n",
    "`Department` indicates the department in the company which the person belongs to, and `ManagementSalary` indicates whether that person is receiving a management position salary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2A - Salary Prediction \n",
    "\n",
    "** Using network `G`, identify the people in the network with missing values for the node attribute `ManagementSalary` and predict whether or not these individuals are receiving a management position salary.**\n",
    "\n",
    "<br>\n",
    "To accomplish this, create a matrix of node features using networkx, train a sklearn classifier on nodes that have `ManagementSalary` data, and predict a probability of the node receiving a management salary for nodes where `ManagementSalary` is missing.\n",
    "\n",
    "Let predictions represent the probability that the corresponding employee is receiving a management position salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: Graph\n",
      "Number of nodes: 1005\n",
      "Number of edges: 16706\n",
      "Average degree:  33.2458\n"
     ]
    }
   ],
   "source": [
    "G = nx.read_gpickle('email_prediction.txt')\n",
    "\n",
    "print(nx.info(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model - AUC Score: 0.9257 (according to Coursera's grader)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create training and testing dataframes:\n",
    "def create_df(dictionary):\n",
    "    \n",
    "    # Training/Testing dataframe of management salary\n",
    "    df = pd.DataFrame.from_dict(dictionary, orient='index').rename(columns={0: \"Target\"})\n",
    "    \n",
    "    # Centrality Measures\n",
    "    ## Note: Centrality measures must be calculated using the entire network. Once calculated, we can streamline via merge.\n",
    "    centrality = [nx.degree_centrality(G), nx.closeness_centrality(G), nx.betweenness_centrality(G)]\n",
    "    centrality_df = pd.DataFrame(centrality).T.rename(columns={0: \"Degree\", 1: \"Closeness\", 2: \"Betweeness\"})\n",
    "    \n",
    "    # Merge centrality measures with the training/testing dataframe\n",
    "    df = centrality_df.merge(df, how='inner', left_index=True, right_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Task: Target Value Prediction\n",
    "def salary_predictions():\n",
    "\n",
    "    # A) Create training and testing features for target (ManagementSalary)\n",
    "    salary = nx.get_node_attributes(G, \"ManagementSalary\")\n",
    "\n",
    "    ## Training: Contains only existing data. Denotes if employee receives management salary (0 is no, 1 is yes)\n",
    "    train_dict = {k:v for k,v in salary.items() if np.isfinite(v)}\n",
    "    train = create_df(train_dict)\n",
    "\n",
    "    ## Testing: Contains missing data. Predict probability that employee receives management salary\n",
    "    test_dict = {k:v for k,v in salary.items() if np.isnan(v)}\n",
    "    test = create_df(test_dict)\n",
    "\n",
    "    \n",
    "    # B) Classifier.\n",
    "    final = LogisticRegression(random_state=0).fit(train.iloc[:,:-1], train.iloc[:,-1])\n",
    "    \n",
    "    ## Make predictions on target using the test set\n",
    "    y_hat = pd.Series(final.predict_proba(test.iloc[:,:-1])[:,1], index=test.index, dtype='float64')\n",
    "    return y_hat\n",
    "\n",
    "salary_predictions().head()\n",
    "print('Final model - AUC Score: 0.9257 (according to Coursera\\'s grader)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2B - New Connections Prediction\n",
    "\n",
    "The last part of the assignment involves **predicting future connections between employees** of the network. \n",
    "\n",
    "The future connections information has been loaded into the variable `future_connections`. The index is a tuple indicating a pair of nodes that currently do not have a connection, and the `Future Connection` column indicates if an edge between those two nodes will exist in the future, where a value of 1.0 indicates a future connection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using network `G` and `future_connections`, identify the edges in `future_connections` with missing values and predict whether or not these edges will have a future connection.\n",
    "\n",
    "To accomplish this, create a matrix of features for the edges found in `future_connections` using networkx. Then, train a sklearn classifier on those edges in `future_connections` that have `Future Connection` data, and predict a probability of the edge being a future connection for those edges in `future_connections` where `Future Connection` is missing.\n",
    "\n",
    "Let predictions represent the probability of the corresponding edge being a future connection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Future Connection</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(6, 840)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(4, 197)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(620, 979)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(519, 872)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(382, 423)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(97, 226)</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(349, 905)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(429, 860)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(309, 989)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(468, 880)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Future Connection\n",
       "(6, 840)                  0.0\n",
       "(4, 197)                  0.0\n",
       "(620, 979)                0.0\n",
       "(519, 872)                0.0\n",
       "(382, 423)                0.0\n",
       "(97, 226)                 1.0\n",
       "(349, 905)                0.0\n",
       "(429, 860)                0.0\n",
       "(309, 989)                0.0\n",
       "(468, 880)                0.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_connections = pd.read_csv('Future_Connections.csv', index_col=0, converters={0: eval})\n",
    "future_connections.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final model - AUC Score: 0.9102 (according to Coursera's grader)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Task: Link Prediction\n",
    "def new_connections_predictions():\n",
    "\n",
    "    # A) Find features for target (Future_Connection)\n",
    "    ind = future_connections.index\n",
    "\n",
    "    ## Apply one node functions to employee pairs:\n",
    "    one_node = [nx.preferential_attachment(G, ind), nx.jaccard_coefficient(G, ind), nx.resource_allocation_index(G, ind), \n",
    "    nx.adamic_adar_index(G, ind)]\n",
    "    names = ['Pref_Attachment', 'Jaccard', 'Resource_Alloc', 'Adamic_Adar']\n",
    "\n",
    "    for fun in range(len(one_node)):\n",
    "        future_connections[names[fun]] = [i[2] for i in one_node[fun]]\n",
    "\n",
    "    ## Apply two node function to employee pairs:\n",
    "    future_connections['Comm_Neighbors'] = ind.map(lambda e: len(list(nx.common_neighbors(G, e[0], e[1]))))\n",
    "\n",
    "\n",
    "    # B) Create training and testing data, for node pair without onnection (index)\n",
    "    target = future_connections['Future Connection']\n",
    "\n",
    "    ## Training: Contains only existing data. Denotes if pair will have future connection(0 is no, 1 is yes)\n",
    "    train =  future_connections[target.notnull()]\n",
    "    ## Testing: Contains missing data. Predict probability that pair will be a future connection\n",
    "    test = future_connections[target.isnull()]\n",
    "\n",
    "    \n",
    "    # C) Classifier\n",
    "    final = GradientBoostingClassifier(random_state=0).fit(train.iloc[:, 1:len(train)], train.iloc[:, 0])\n",
    "\n",
    "    ## Make predictions on target using the test set\n",
    "    y_hat = pd.Series(final.predict_proba(test.iloc[:, 1:len(test)])[:,1], index=test.index, dtype='float64')\n",
    "    \n",
    "    return y_hat\n",
    "\n",
    "new_connections_predictions()\n",
    "print('Final model - AUC Score: 0.9102 (according to Coursera\\'s grader)')"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-social-network-analysis",
   "graded_item_id": "BGNwe",
   "launcher_item_id": "rMoj0",
   "part_id": "E2zRG"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
